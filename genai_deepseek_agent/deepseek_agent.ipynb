{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c727fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from agno.agent import Agent\n",
    "from agno.models.ollama import Ollama\n",
    "from agno.models.google import Gemini\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "from agno.vectordb.chroma import ChromaDb\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCr35hxFrpVsbNWgqOwU6PwmkpwLmO2dJA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e001b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"deepseek_rag\"\n",
    "CHROMA_PATH = \"./chroma_db\"\n",
    "EMBEDDING_MODEL = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "MODEL_VERSION = \"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize ChromaDB ---\n",
    "def init_chroma():\n",
    "    chroma = ChromaDb(\n",
    "        collection=COLLECTION_NAME,\n",
    "        path=CHROMA_PATH,\n",
    "        embedder=EMBEDDING_MODEL,\n",
    "        persistent_client=True\n",
    "    )\n",
    "    try:\n",
    "        chroma.client.get_collection(name=COLLECTION_NAME)\n",
    "    except Exception:\n",
    "        chroma.create()\n",
    "    return chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec180304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split documents into chunks ---\n",
    "def split_texts(documents):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    return [Document(page_content=chunk.page_content, metadata=chunk.metadata) for chunk in chunks if chunk.page_content.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process PDF Files ---\n",
    "def process_pdf(file_path, file_name):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    for doc in documents:\n",
    "        doc.metadata.update({\n",
    "            \"source_type\": \"pdf\",\n",
    "            \"file_name\": file_name,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "    return split_texts(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0200bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process Web URL ---\n",
    "def process_web(url):\n",
    "    loader = WebBaseLoader(url)\n",
    "    documents = loader.load()\n",
    "    for doc in documents:\n",
    "        doc.metadata.update({\n",
    "            \"source\": url,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "    return split_texts(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2cf535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Retrieve Documents ---\n",
    "def retrieve_documents(prompt, chroma_client, threshold=0.7):\n",
    "    collection = chroma_client.client.get_collection(name=COLLECTION_NAME)\n",
    "    results = collection.query(query_texts=[prompt], n_results=5)\n",
    "    docs = results.get('documents', [])\n",
    "    return docs, len(docs) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filter <think> tags ---\n",
    "def filter_think_tags(response):\n",
    "    return re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8500609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Agents ---\n",
    "def get_rag_agent():\n",
    "    return Agent(\n",
    "        name=\"DeepSeek RAG Agent\",\n",
    "        model=Ollama(id=MODEL_VERSION),\n",
    "        instructions=\"Answer using the most relevant available information.\",\n",
    "        markdown=True,\n",
    "    )\n",
    "\n",
    "def get_web_search_agent():\n",
    "    return Agent(\n",
    "        name=\"Web Search Agent\",\n",
    "        model=Gemini(id=\"gemini-2.0-flash-exp\"),\n",
    "        tools=[DuckDuckGoTools()],\n",
    "        instructions=\"Search the web using DuckDuckGo and summarize key points.\",\n",
    "        markdown=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1078ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(prompt, chroma_client, use_rag=True, use_web_search=False, force_web_search=False):\n",
    "    context = \"\"\n",
    "\n",
    "    if use_rag and not force_web_search:\n",
    "        docs, found = retrieve_documents(prompt, chroma_client)\n",
    "        if found:\n",
    "            flattened = [p for doc in docs for p in doc]\n",
    "            context = \"\\n\\n\".join(flattened)\n",
    "\n",
    "    if (not context or force_web_search) and use_web_search:\n",
    "        print(\"Running web search...\")\n",
    "        web_agent = get_web_search_agent()\n",
    "        web_results = web_agent.run(prompt).content\n",
    "        if web_results:\n",
    "            context = f\"Web Search Results:\\n{web_results}\"\n",
    "\n",
    "    print(\"Generating response...\")\n",
    "    agent = get_rag_agent()\n",
    "    response = agent.run(f\"Context: {context}\\n\\nQuestion: {prompt}\").content\n",
    "    return filter_think_tags(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = init_chroma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa97aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"sample.pdf\"\n",
    "if os.path.exists(pdf_path):\n",
    "    pdf_chunks = process_pdf(pdf_path, \"sample.pdf\")\n",
    "    ids = [str(i) for i in range(len(pdf_chunks))]\n",
    "    texts = [doc.page_content for doc in pdf_chunks]\n",
    "    metadatas = [doc.metadata for doc in pdf_chunks]\n",
    "    chroma_client.client.get_collection(name=COLLECTION_NAME).add(\n",
    "        ids=ids, documents=texts, metadatas=metadatas\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_url = \"https://en.wikipedia.org/wiki/Artificial_intelligence\"\n",
    "web_chunks = process_web(web_url)\n",
    "ids = [str(i + 10000) for i in range(len(web_chunks))]\n",
    "texts = [doc.page_content for doc in web_chunks]\n",
    "metadatas = [doc.metadata for doc in web_chunks]\n",
    "chroma_client.client.get_collection(name=COLLECTION_NAME).add(\n",
    "    ids=ids, documents=texts, metadatas=metadatas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Artificial Intelligence?\"\n",
    "answer = answer_question(query, chroma_client, use_rag=True, use_web_search=True)\n",
    "print(f\"\\nðŸ§  Answer:\\n{answer}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
